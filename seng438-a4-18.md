**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group \#: 18            |
| ------------------------|
| Mohammed Momin Ali Khan | 
| Nicole Zacaruk          |
| Braden Foley            |
| Ethan Sengsavang        |

# Introduction
The lab was divided into two sections, namely Mutation Testing and GUI Testing. In the first section, we checked mutation faults in a Java code-base by using a mutation testing tool and learnt how to interpret the mutation scores and used that information to create new test cases, thereby improving the quality of the overall test suite. The second section focuses on the widely used method of GUI test automation. We used Selenium, a well-known tool for web interface testing, and compared it with an alternative tool.

# Analysis of 10 Mutants of the Range class 

### Test Suites used: 
testGetCentralValueRange1(), testGetCentralValueRange2(), testGetCentralValueRange3()

### Mutants contained in the method: 
getCentralValue()

- **Mutant 1**: Substituted 2.0 with 1.0 → KILLED
- **How it was killed or not**: The mutant initially survived however, when substituted with 1, our test would fail and hence kill the mutant. This results in the **mutant being killed**.

- **Mutant 2**: Replaced double division with multiplication → KILLED
- **How it was killed or not**: This mutant changes the division operator to multiplication, however, our test identified and since the expected value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 3**: Replaced double addition with subtraction → KILLED
- **How it was killed or not**: This mutant changes the addition operator of the double input to subtraction, however, our test identified and since the expected value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 4**: replaced double return with 0.0d for org/jfree/data/Range::getCentralValue → KILLED
- **How it was killed or not**: This mutant changes the return value of the getCentralValue, however, our test identified and since the expected function value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 5**: Replaced double addition with multiplication → KILLED
- **How it was killed or not**: This mutant changes the operator being used from addition of the double numbers to multiplication, however, our test identified that and since the expected function value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 6**: Negated double field upper → KILLED
- **How it was killed or not**: This mutant changes the double field upper value to be negative, however, we have a test case for that which was identified and since the expected function value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 7**: Negated double field upper → KILLED
- **How it was killed or not**: This mutant changes the double field upper value to be negative, however, we have a test case for that which was identified and since the expected function value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 8**: replaced return of double value with -(x + 1) for org/jfree/data/Range::getCentralValue → KILLED
- **How it was killed or not**: This mutant changes the double return value to be negative of (x+1), but the test cases defined and mentioned above as well, this mutant was identified and since the expected function value did not match, the mutant was killed. Hence, the result of **mutant being killed**.

- **Mutant 9**: Incremented (a++) double field lower → SURVIVED
- **How it was killed or not**: This mutant changes the double field lower's value after and increments it and is identified as an equivalent mutant. Since this change is a local change, it does not exist anymore when the test returns and hence, the result of **mutant surviving**.

- **Mutant 10**: Decremented (a--) double field lower → SURVIVED
- **How it was killed or not**: This mutant changes the double field lower's value after and decrements it and is identified as an equivalent mutant. Since this change is a local change, it does not exist anymore when the test returns and hence, the result of **mutant surviving**.



# Report all the statistics and the mutation score for each test class

Range before:
![Mutation coverage of Range before](media/Mutation_Range_before.png)

Range After:
![Mutation coverage of Range before](media/Mutation_Range_After.png)

DataUtilities Before:
![Mutation coverage of DataUtilities before](media/Mutation_DataUtilites_Coverage.png)

> Note: with an initial mutation coverage of 88%, it was extremely difficult to increase our mutation coverage by 10% no
> matter what was tried. Any changes would not increase the mutation coverage at all.

# Analysis drawn on the effectiveness of each of the test classes

## Range Class

Upon reviewing the efficacy of our mutation coverage for the range test class, we identified several crucial factors. One significant finding was that our initial mutation coverage was only 62%, which was surprising since we had achieved high coverage but we figured out that the mutation coverage was not high enough still in the previous assignment. Upon further inspection of the summary log, we discovered that certain areas of the code were not receiving as much testing as we had anticipated, resulting in a high number of surviving mutants, particularly equivalence mutants. To address this issue, we decided to create new test cases for our previous test suites with a focus on targeting these equivalence mutants and increasing mutation coverage by eliminating numerous mutants with a single test. We noted that the get() methods, expands(), and equals() contained a large number of surviving mutants. To increase the mutation coverage over the 10% threshold, we tried to create detailed and specific test cases for these methods. We eventually included new tests and even for the class shiftWithNoZeroCrossing(), but it is still important to note that the presence of equivalence mutants adversely affects the accuracy of the mutation score. Several tests were added and some of them are: testIntersectsOneNanRange(), testGetCentralValueRange1(),shiftTestNoCrossPositiveBounds().

## DataUtilities Class

The core issue within tests were that mocked classes were not robust enough to detect when exceptions were supposed to be thrown. An example of this could be seen with the conditional checks within the for loops of methods like `calculateRowTotal`. Particularly within `calculateRowTotal`, these situations led the mocked object to return `null` on an index equal to the size of the column being traversed. Therefore, additional boundry checks, and proper exception *throwing* were created to ensure these mutants are caught.


# A discussion on the effect of equivalent mutants on mutation score accuracy

Equivalent mutants lowers score accuracy as an error is added, but the behaviour is the same. As a result, it is difficult for a test to determine if a mutant was created as there is no direct change in the behaviour of the tested method itself. However, Equivalent mutants are still notable, as it may be the case that those mutations do not affect the value returned from a method, but possibly values that were passed into the method as parameters, particularly via reference over value.

# A discussion of what could have been done to improve the mutation score of the test suites

A better mutation score could be achieved by more robust tests, accounting for values above and below the boundries of equivalent classes. Along with this, proper exception throwing within any mocked objects can catch mutations that would generally be illogical. These cases include when the inputted index of a mocked array-like object goes out of bounds, for example.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is really helpful as it can identify issues that were originally not caught within other tests with 100% coverage. Although 100% path or branch coverage is achieved, there could continue to be edge cases that are left unconsidered by the developer that may persist. By generating purposefully buggy, but all-around similar code, a tester can be confident that a test case is effective when that mutation is caught. As a result, mutation testing is beneficial for validating the strength of a test suite.

### Advantages

- Thorough and deliberate
    - if an issue were to exist within a test case, it can be easily identified if a mutation is left uncaught.
- Simple in concept
    - it may be easier to discuss issues with mutation coverage  or strength across a team
- may identify additional bugs within the software
    - Although its primary function is to check the strength of a test suite, if a very particular case were to spring up within a source code, that is another possible source of failure that has been identified and can be fixed.

### Disadvantages

- Very time and resource consuming
    - The process to make several small changes to a large code base is extremely lengthy and costly
- False positives may arise
    - as discussed above, equivalent mutations may lead to inaccuracies about a test suite's strength coverage. As a computer is simply making practically random adjustments to values, the mutations may lead to logically equivalent code which would not be an issue at all.

# Explain your SELENUIM test case design process

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# Discuss advantages and disadvantages of Selenium vs. Sikulix

# How the team work/effort was divided and managed


# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the lab itself
